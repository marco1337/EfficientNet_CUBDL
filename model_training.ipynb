{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scoring.make_rois_point import rois_point\n",
    "from scoring.make_rois_image import rois_image\n",
    "from scoring.make_rois_lesion import rois_lesion\n",
    "from scoring.make_rois_speckle import rois_speckle\n",
    "from scoring.make_rois_additional import rois_additional\n",
    "from cubdl.das_torch import DAS_PW\n",
    "from scoring.measure_picmus import measure_picmus\n",
    "from scoring.measure_point import measure_point\n",
    "from scoring.measure_image import measure_image\n",
    "from scoring.measure_lesion import measure_lesion\n",
    "from scoring.measure_speckle import measure_speckle\n",
    "from scoring.measure_additional import measure_additional\n",
    "import os\n",
    "from datasets.PWDataLoaders import load_data\n",
    "from cubdl.PlaneWaveData import PlaneWaveData\n",
    "import h5py\n",
    "from glob import glob\n",
    "from scipy.signal import hilbert, convolve\n",
    "from cubdl.PixelGrid import make_pixel_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class INSData(PlaneWaveData):\n",
    "    \"\"\" Load data from INSERM. \"\"\"\n",
    "    def __init__(self, database_path, acq):\n",
    "        # Make sure the selected dataset is valid\n",
    "        moniker = \"INS{:03d}\".format(acq) + \"*.hdf5\"\n",
    "        fname = [\n",
    "            y for x in os.walk(database_path) for y in glob(os.path.join(x[0], moniker))\n",
    "        ]\n",
    "        assert fname, \"File not found.\"\n",
    "\n",
    "        # Load dataset\n",
    "        f = h5py.File(fname[0], \"r\")\n",
    "\n",
    "        # Phantom-specific parameters\n",
    "        if acq == 1:\n",
    "            sound_speed = 1521\n",
    "        elif acq == 2:\n",
    "            sound_speed = 1517\n",
    "        elif acq == 3:\n",
    "            sound_speed = 1506\n",
    "        elif acq == 4:\n",
    "            sound_speed = 1501\n",
    "        elif acq == 5:\n",
    "            sound_speed = 1506\n",
    "        elif acq == 6:\n",
    "            sound_speed = 1509\n",
    "        elif acq == 7:\n",
    "            sound_speed = 1490\n",
    "        elif acq == 8:\n",
    "            sound_speed = 1504\n",
    "        elif acq == 9:\n",
    "            sound_speed = 1473\n",
    "        elif acq == 10:\n",
    "            sound_speed = 1502\n",
    "        elif acq == 11:\n",
    "            sound_speed = 1511\n",
    "        elif acq == 12:\n",
    "            sound_speed = 1535\n",
    "        elif acq == 13:\n",
    "            sound_speed = 1453\n",
    "        elif acq == 14:\n",
    "            sound_speed = 1542\n",
    "        elif acq == 15:\n",
    "            sound_speed = 1539\n",
    "        elif acq == 16:\n",
    "            sound_speed = 1466\n",
    "        elif acq == 17:\n",
    "            sound_speed = 1462\n",
    "        elif acq == 18:\n",
    "            sound_speed = 1479\n",
    "        elif acq == 19:\n",
    "            sound_speed = 1469\n",
    "        elif acq == 20:\n",
    "            sound_speed = 1464\n",
    "        elif acq == 21:\n",
    "            sound_speed = 1508\n",
    "        elif acq == 22:\n",
    "            sound_speed = 1558\n",
    "        elif acq == 23:\n",
    "            sound_speed = 1463\n",
    "        elif acq == 24:\n",
    "            sound_speed = 1547\n",
    "        elif acq == 25:\n",
    "            sound_speed = 1477\n",
    "        elif acq == 26:\n",
    "            sound_speed = 1497\n",
    "        else:\n",
    "            sound_speed = 1540\n",
    "\n",
    "        # Get data\n",
    "        self.idata = np.array(f[\"channel_data\"], dtype=\"float32\")\n",
    "        self.qdata = np.imag(hilbert(self.idata, axis=-1))\n",
    "        self.angles = np.linspace(-16, 16, self.idata.shape[0]) * np.pi / 180\n",
    "        self.fc = np.array(f[\"modulation_frequency\"]).item()\n",
    "        self.fs = np.array(f[\"sampling_frequency\"]).item()\n",
    "        self.c = sound_speed  # np.array(f[\"sound_speed\"]).item()\n",
    "        self.time_zero = -1 * np.array(f[\"start_time\"], dtype=\"float32\")[0]\n",
    "        self.fdemod = 0\n",
    "        self.ele_pos = np.array(f[\"element_positions\"], dtype=\"float32\").T\n",
    "        self.ele_pos[:, 0] -= np.mean(self.ele_pos[:, 0])\n",
    "\n",
    "        # For this dataset, time zero is the center point\n",
    "        for i, a in enumerate(self.angles):\n",
    "            self.time_zero[i] += self.ele_pos[-1, 0] * np.abs(np.sin(a)) / self.c\n",
    "\n",
    "        # Validate that all information is properly included\n",
    "        super().validate()\n",
    "\n",
    "class MYOData(PlaneWaveData):\n",
    "    \"\"\" Load data from Mayo Clinic. \"\"\"\n",
    "\n",
    "    def __init__(self, database_path, acq):\n",
    "        # Make sure the selected dataset is valid\n",
    "        moniker = \"MYO{:03d}\".format(acq) + \"*.hdf5\"\n",
    "        fname = [\n",
    "            y for x in os.walk(database_path) for y in glob(os.path.join(x[0], moniker))\n",
    "        ]\n",
    "        assert fname, \"File not found.\"\n",
    "\n",
    "        # Load dataset\n",
    "        f = h5py.File(fname[0], \"r\")\n",
    "\n",
    "        # Phantom-specific parameters\n",
    "        if acq == 1:\n",
    "            sound_speed = 1580\n",
    "        elif acq == 2:\n",
    "            sound_speed = 1583\n",
    "        elif acq == 3:\n",
    "            sound_speed = 1578\n",
    "        elif acq == 4:\n",
    "            sound_speed = 1572\n",
    "        elif acq == 5:\n",
    "            sound_speed = 1562\n",
    "        else:\n",
    "            sound_speed = 1581\n",
    "\n",
    "        # Get data\n",
    "        self.idata = np.array(f[\"channel_data\"], dtype=\"float32\")\n",
    "        self.qdata = np.imag(hilbert(self.idata, axis=-1))\n",
    "        self.angles = np.array(f[\"angles\"])\n",
    "        self.fc = np.array(f[\"modulation_frequency\"]).item()\n",
    "        self.fs = np.array(f[\"sampling_frequency\"]).item()\n",
    "        self.c = sound_speed  # np.array(f[\"sound_speed\"]).item()\n",
    "        self.time_zero = np.zeros((len(self.angles),), dtype=\"float32\")\n",
    "        self.fdemod = 0\n",
    "\n",
    "        # Make the element positions based on L11-4v geometry\n",
    "        pitch = 0.3e-3\n",
    "        nelems = self.idata.shape[1]\n",
    "        xpos = np.arange(nelems) * pitch\n",
    "        xpos -= np.mean(xpos)\n",
    "        self.ele_pos = np.stack([xpos, 0 * xpos, 0 * xpos], axis=1)\n",
    "\n",
    "        # For this dataset, time zero is the center point\n",
    "        for i, a in enumerate(self.angles):\n",
    "            self.time_zero[i] = self.ele_pos[-1, 0] * np.abs(np.sin(a)) / self.c\n",
    "\n",
    "        # Validate that all information is properly included\n",
    "        super().validate()\n",
    "\n",
    "class OSLData(PlaneWaveData):\n",
    "    \"\"\" Load data from University of Oslo. \"\"\"\n",
    "\n",
    "    def __init__(self, database_path, acq):\n",
    "\n",
    "        # Make sure the selected dataset is valid\n",
    "        moniker = \"OSL{:03d}\".format(acq) + \".hdf5\"\n",
    "        fname = [\n",
    "            y for x in os.walk(database_path) for y in glob(os.path.join(x[0], moniker))\n",
    "        ]\n",
    "        assert fname, \"File not found.\"\n",
    "        assert acq in [2, 3, 4, 5, 6, 7, 10], \"Focused Data. Use FTDataLoaders\"\n",
    "\n",
    "        # Load dataset\n",
    "        f = h5py.File(fname[0], \"r\")\n",
    "\n",
    "        # Phantom-specific parameters\n",
    "        if acq == 2:\n",
    "            sound_speed = 1536\n",
    "        elif acq == 3:\n",
    "            sound_speed = 1543\n",
    "        elif acq == 4:\n",
    "            sound_speed = 1538\n",
    "        elif acq == 5:\n",
    "            sound_speed = 1539\n",
    "        elif acq == 6:\n",
    "            sound_speed = 1541\n",
    "        elif acq == 7:\n",
    "            sound_speed = 1540\n",
    "        else:\n",
    "            sound_speed = 1540\n",
    "\n",
    "        # Get data\n",
    "        self.idata = np.array(f[\"channel_data\"], dtype=\"float32\")\n",
    "        self.qdata = np.imag(hilbert(self.idata, axis=-1))\n",
    "        self.angles = np.array(f[\"transmit_direction\"][0], dtype=\"float32\")\n",
    "        self.fc = np.array(f[\"modulation_frequency\"]).item()\n",
    "        self.fs = np.array(f[\"sampling_frequency\"]).item()\n",
    "        self.c = sound_speed  # np.array(f[\"sound_speed\"]).item()\n",
    "        self.time_zero = -1 * np.array(f[\"start_time\"], dtype=\"float32\")[0]\n",
    "        self.fdemod = 0\n",
    "        self.ele_pos = np.array(f[\"element_positions\"], dtype=\"float32\").T\n",
    "        self.ele_pos[:, 0] -= np.mean(self.ele_pos[:, 0])\n",
    "\n",
    "        # Validate that all information is properly included\n",
    "        super().validate()\n",
    "\n",
    "class UFLData(PlaneWaveData):\n",
    "    \"\"\" Load data from UNIFI. \"\"\"\n",
    "\n",
    "    def __init__(self, database_path, acq):\n",
    "        moniker = \"UFL{:03d}\".format(acq) + \"*.hdf5\"\n",
    "        fname = [\n",
    "            y for x in os.walk(database_path) for y in glob(os.path.join(x[0], moniker))\n",
    "        ]\n",
    "        assert fname, \"File not found.\"\n",
    "\n",
    "        # Load dataset\n",
    "        f = h5py.File(fname[0], \"r\")\n",
    "\n",
    "        # Phantom-specific parameters\n",
    "        if acq == 1:\n",
    "            sound_speed = 1526\n",
    "        elif acq == 2 or acq == 4 or acq == 5:\n",
    "            sound_speed = 1523\n",
    "        else:\n",
    "            sound_speed = 1525\n",
    "\n",
    "        # Get data\n",
    "        self.idata = np.array(f[\"channel_data\"], dtype=\"float32\")\n",
    "        self.qdata = np.imag(hilbert(self.idata, axis=-1))\n",
    "        self.angles = np.array(f[\"angles\"]) * np.pi / 180\n",
    "        self.fc = np.array(f[\"modulation_frequency\"]).item()\n",
    "        self.fs = np.array(f[\"channel_data_sampling_frequency\"]).item()\n",
    "        self.c = sound_speed  # np.array(f[\"sound_speed\"]).item()\n",
    "        self.time_zero = -1 * np.array(f[\"channel_data_t0\"], dtype=\"float32\")\n",
    "        self.fdemod = self.fc\n",
    "\n",
    "        # Make the element positions based on LA533 geometry\n",
    "        pitch = 0.245e-3\n",
    "        nelems = self.idata.shape[1]\n",
    "        xpos = np.arange(nelems) * pitch\n",
    "        xpos -= np.mean(xpos)\n",
    "        self.ele_pos = np.stack([xpos, 0 * xpos, 0 * xpos], axis=1)\n",
    "\n",
    "        # Make sure that time_zero is an array of size [nangles]\n",
    "        if self.time_zero.size == 1:\n",
    "            self.time_zero = np.ones_like(self.angles) * self.time_zero\n",
    "\n",
    "        # Demodulate data and low-pass filter\n",
    "        data = self.idata + 1j * self.qdata\n",
    "        phase = np.reshape(np.arange(self.idata.shape[2], dtype=\"float\"), (1, 1, -1))\n",
    "        phase *= self.fdemod / self.fs\n",
    "        data *= np.exp(-2j * np.pi * phase)\n",
    "        dsfactor = int(np.floor(self.fs / self.fc))\n",
    "        kernel = np.ones((1, 1, dsfactor), dtype=\"float\") / dsfactor\n",
    "        data = convolve(data, kernel, \"same\")\n",
    "        data = data[:, :, ::dsfactor]\n",
    "        self.fs /= dsfactor\n",
    "\n",
    "        self.idata = np.real(data)\n",
    "        self.qdata = np.imag(data)\n",
    "\n",
    "        # Validate that all information is properly included\n",
    "        super().validate()\n",
    "\n",
    "class EUTData(PlaneWaveData):\n",
    "    \"\"\" Load data from TU/e. \"\"\"\n",
    "\n",
    "    def __init__(self, database_path, acq):\n",
    "\n",
    "        # Make sure the selected dataset is valid\n",
    "        moniker = \"EUT{:03d}\".format(acq) + \"*.hdf5\"\n",
    "        fname = [\n",
    "            y for x in os.walk(database_path) for y in glob(os.path.join(x[0], moniker))\n",
    "        ]\n",
    "        assert fname, \"File not found.\"\n",
    "\n",
    "        # Load dataset\n",
    "        f = h5py.File(fname[0], \"r\")\n",
    "\n",
    "        # Phantom-specific parameters\n",
    "        if acq == 1:\n",
    "            sound_speed = 1603\n",
    "        elif acq == 2:\n",
    "            sound_speed = 1618\n",
    "        elif acq == 3:\n",
    "            sound_speed = 1607\n",
    "        elif acq == 4:\n",
    "            sound_speed = 1614\n",
    "        elif acq == 5:\n",
    "            sound_speed = 1495\n",
    "        else:\n",
    "            sound_speed = 1479\n",
    "\n",
    "        # Get data\n",
    "        self.idata = np.array(f[\"channel_data\"], dtype=\"float32\")\n",
    "        self.qdata = np.imag(hilbert(self.idata, axis=-1))\n",
    "        self.angles = np.array(f[\"transmit_direction\"])[:, 0]\n",
    "        self.fc = np.array(f[\"modulation_frequency\"]).item()\n",
    "        self.fs = np.array(f[\"sampling_frequency\"]).item()\n",
    "        self.c = sound_speed\n",
    "        self.time_zero = np.array(f[\"start_time\"], dtype=\"float32\")[0]\n",
    "        self.fdemod = 0\n",
    "        self.ele_pos = np.array(f[\"element_positions\"], dtype=\"float32\").T\n",
    "        self.ele_pos[:, 0] -= np.mean(self.ele_pos[:, 0])\n",
    "\n",
    "        # For this dataset, time zero is the center point\n",
    "        for i, a in enumerate(self.angles):\n",
    "            self.time_zero[i] = self.ele_pos[-1, 0] * np.abs(np.sin(a)) / self.c\n",
    "\n",
    "        # Seems to be some offset\n",
    "        self.time_zero += 10 / self.fc\n",
    "\n",
    "        # Validate that all information is properly included\n",
    "        super().validate()\n",
    "        \n",
    "class JHUData(PlaneWaveData):\n",
    "    \"\"\" Load data from University of Oslo. \"\"\"\n",
    "\n",
    "    def __init__(self, database_path, acq):\n",
    "\n",
    "        # Make sure the selected dataset is valid\n",
    "        moniker = \"JHU{:03d}\".format(acq) + \".hdf5\"\n",
    "        fname = [\n",
    "            y for x in os.walk(database_path) for y in glob(os.path.join(x[0], moniker))\n",
    "        ]\n",
    "        assert fname, \"File not found.\"\n",
    "        assert acq in list(range(24, 35)), \"Focused Data. Use FTDataLoaders\"\n",
    "\n",
    "        # Load dataset\n",
    "        f = h5py.File(fname[0], \"r\")\n",
    "\n",
    "        # Get data\n",
    "        self.idata = np.array(f[\"channel_data\"], dtype=\"float32\")\n",
    "        self.qdata = np.imag(hilbert(self.idata, axis=-1))\n",
    "        self.angles = np.array(f[\"angles\"])\n",
    "        self.fc = np.array(f[\"modulation_frequency\"]).item()\n",
    "        self.fs = np.array(f[\"sampling_frequency\"]).item()\n",
    "        self.c = np.array(f[\"sound_speed\"]).item()\n",
    "        self.time_zero = -1 * np.array(f[\"time_zero\"], dtype=\"float32\")\n",
    "        self.fdemod = 0\n",
    "\n",
    "        xpos = np.array(f[\"element_positions\"], dtype=\"float32\").T\n",
    "        self.ele_pos = np.stack([xpos, 0 * xpos, 0 * xpos], axis=1)\n",
    "        self.zlims = np.array([0e-3, self.idata.shape[2] * self.c / self.fs / 2])\n",
    "        self.xlims = np.array([self.ele_pos[0, 0], self.ele_pos[-1, 0]])\n",
    "\n",
    "        # For this dataset, time zero is the center point\n",
    "        # self.time_zero = np.zeros((len(self.angles),), dtype=\"float32\")\n",
    "        # for i, a in enumerate(self.angles):\n",
    "        #     self.time_zero[i] = self.ele_pos[-1, 0] * np.abs(np.sin(a)) / self.c\n",
    "\n",
    "        # Seems to be some offset\n",
    "        # self.time_zero -= 10 / self.fc\n",
    "\n",
    "        # Validate that all information is properly included\n",
    "        super().validate()\n",
    "\n",
    "class TSHData(PlaneWaveData):\n",
    "    \"\"\" Load data from Tsinghua University. \"\"\"\n",
    "\n",
    "    def __init__(self, database_path, acq):\n",
    "        # Make sure the selected dataset is valid\n",
    "        moniker = \"TSH{:03d}\".format(acq) + \"*.hdf5\"\n",
    "        fname = [\n",
    "            y for x in os.walk(database_path) for y in glob(os.path.join(x[0], moniker))\n",
    "        ]\n",
    "        assert fname, \"File not found.\"\n",
    "\n",
    "        # Load dataset\n",
    "        f = h5py.File(fname[0], \"r\")\n",
    "\n",
    "        # Get data\n",
    "        self.angles = np.array(f[\"angles\"])\n",
    "        self.idata = np.array(f[\"channel_data\"], dtype=\"float32\")\n",
    "        self.idata = np.reshape(self.idata, (128, len(self.angles), -1))\n",
    "        self.idata = np.transpose(self.idata, (1, 0, 2))\n",
    "        self.qdata = np.imag(hilbert(self.idata, axis=-1))\n",
    "        self.fc = np.array(f[\"modulation_frequency\"]).item()\n",
    "        self.fs = np.array(f[\"sampling_frequency\"]).item()\n",
    "        self.c = 1540  # np.array(f[\"sound_speed\"]).item()\n",
    "        self.time_zero = np.zeros((len(self.angles),), dtype=\"float32\")\n",
    "        self.fdemod = 0\n",
    "\n",
    "        # Make the element positions based on L11-4v geometry\n",
    "        pitch = 0.3e-3\n",
    "        nelems = self.idata.shape[1]\n",
    "        xpos = np.arange(nelems) * pitch\n",
    "        xpos -= np.mean(xpos)\n",
    "        self.ele_pos = np.stack([xpos, 0 * xpos, 0 * xpos], axis=1)\n",
    "\n",
    "        # For this dataset, time zero is the center point\n",
    "        for i, a in enumerate(self.angles):\n",
    "            self.time_zero[i] = self.ele_pos[-1, 0] * np.abs(np.sin(a)) / self.c\n",
    "\n",
    "        # Validate that all information is properly included\n",
    "        super().validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_and_acq(filename):\n",
    "    file_text = os.path.splitext(filename)\n",
    "    name = file_text[0]\n",
    "    number = int(name[-3:])\n",
    "    origin = name[0:3]\n",
    "    return origin, number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = r'D:\\OneDrive\\Documents\\Maestria_Biomedica\\Imagenes_Medicas\\model_cubdl\\TSH'\n",
    "files = os.listdir(path1)\n",
    "\n",
    "max_rows = 0\n",
    "max_columns = 0 \n",
    "\n",
    "for file in files:\n",
    "    if file.endswith(\".hdf5\"):\n",
    "        print(file)\n",
    "        origin, acq = get_name_and_acq(file)\n",
    "        # print(os.path.abspath(file))\n",
    "        full_path = os.path.abspath(file)\n",
    "        if origin== 'MYO':\n",
    "            print(file)\n",
    "            P = MYOData(path1, acq)\n",
    "            xlims = [P.ele_pos[0, 0], P.ele_pos[-1, 0]]\n",
    "            zlims = [5e-3, 55e-3]\n",
    "        elif origin == 'INS':\n",
    "            P = INSData(path1, acq)\n",
    "            xlims = [P.ele_pos[0, 0], P.ele_pos[-1, 0]]\n",
    "            zlims = [10e-3, 60e-3]\n",
    "            if acq >= 13:\n",
    "                zlims = [10e-3, 50e-3]\n",
    "        elif origin == 'UFL':\n",
    "            P = UFLData(path1, acq)\n",
    "            xlims = [P.ele_pos[0, 0], P.ele_pos[-1, 0]]\n",
    "            zlims = [10e-3, 50e-3]\n",
    "        elif origin == 'OSL':\n",
    "            P = OSLData(path1, acq)\n",
    "            xlims = [P.ele_pos[0, 0], P.ele_pos[-1, 0]]\n",
    "            zlims = [10e-3, 65e-3]\n",
    "            if acq == 10:\n",
    "                zlims = [5e-3, 50e-3]\n",
    "        elif origin == 'EUT':\n",
    "            P = EUTData(path1, acq)\n",
    "            xlims = [P.ele_pos[0, 0], P.ele_pos[-1, 0]]\n",
    "            zlims = [10e-3, 80e-3]\n",
    "        elif origin == 'JHU':\n",
    "            P = JHUData(path1, acq)\n",
    "            xlims = [P.ele_pos[0, 0], P.ele_pos[-1, 0]]\n",
    "            zlims = [0e-3, 30e-3]\n",
    "        elif origin == 'TSH':\n",
    "            P = TSHData(path1, acq)\n",
    "            xlims = [P.ele_pos[0, 0], P.ele_pos[-1, 0]]\n",
    "            zlims = [10e-3, 45e-3]\n",
    "        \n",
    "        wvln = P.c / P.fc\n",
    "        dx = wvln / 2.5\n",
    "        dz = dx  # Use square pixels\n",
    "        grid = make_pixel_grid(xlims, zlims, dx, dz)\n",
    "        fnum = 1\n",
    "\n",
    "        x = (P.idata, P.qdata)\n",
    "        idx = len(P.angles) // 2  # Choose center angle\n",
    "        das1 = DAS_PW(P, grid, idx, rxfnum=fnum)\n",
    "        idas1, qdas1 = das1(x)\n",
    "        idas1, qdas1 = idas1.detach().cpu().numpy(), qdas1.detach().cpu().numpy()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import time\n",
    "import logging\n",
    "import argparse\n",
    "from efficientnet_lite import efficientnet_lite_params, build_efficientnet_lite\n",
    "from utils.train_utils import accuracy, AvgrageMeter, CrossEntropyLabelSmooth, save_checkpoint, get_lastest_model, get_parameters\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 178, 194]             576\n",
      "       BatchNorm2d-2         [-1, 32, 178, 194]              64\n",
      "             ReLU6-3         [-1, 32, 178, 194]               0\n",
      "            Conv2d-4         [-1, 32, 178, 194]             288\n",
      "       BatchNorm2d-5         [-1, 32, 178, 194]              64\n",
      "             ReLU6-6         [-1, 32, 178, 194]               0\n",
      "            Conv2d-7         [-1, 16, 178, 194]             512\n",
      "       BatchNorm2d-8         [-1, 16, 178, 194]              32\n",
      "       MBConvBlock-9         [-1, 16, 178, 194]               0\n",
      "           Conv2d-10         [-1, 96, 178, 194]           1,536\n",
      "      BatchNorm2d-11         [-1, 96, 178, 194]             192\n",
      "            ReLU6-12         [-1, 96, 178, 194]               0\n",
      "           Conv2d-13           [-1, 96, 89, 97]             864\n",
      "      BatchNorm2d-14           [-1, 96, 89, 97]             192\n",
      "            ReLU6-15           [-1, 96, 89, 97]               0\n",
      "           Conv2d-16           [-1, 24, 89, 97]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 89, 97]              48\n",
      "      MBConvBlock-18           [-1, 24, 89, 97]               0\n",
      "           Conv2d-19          [-1, 144, 89, 97]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 89, 97]             288\n",
      "            ReLU6-21          [-1, 144, 89, 97]               0\n",
      "           Conv2d-22          [-1, 144, 89, 97]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 89, 97]             288\n",
      "            ReLU6-24          [-1, 144, 89, 97]               0\n",
      "           Conv2d-25           [-1, 24, 89, 97]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 89, 97]              48\n",
      "      MBConvBlock-27           [-1, 24, 89, 97]               0\n",
      "           Conv2d-28          [-1, 144, 89, 97]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 89, 97]             288\n",
      "            ReLU6-30          [-1, 144, 89, 97]               0\n",
      "           Conv2d-31          [-1, 144, 45, 49]           3,600\n",
      "      BatchNorm2d-32          [-1, 144, 45, 49]             288\n",
      "            ReLU6-33          [-1, 144, 45, 49]               0\n",
      "           Conv2d-34           [-1, 40, 45, 49]           5,760\n",
      "      BatchNorm2d-35           [-1, 40, 45, 49]              80\n",
      "      MBConvBlock-36           [-1, 40, 45, 49]               0\n",
      "           Conv2d-37          [-1, 240, 45, 49]           9,600\n",
      "      BatchNorm2d-38          [-1, 240, 45, 49]             480\n",
      "            ReLU6-39          [-1, 240, 45, 49]               0\n",
      "           Conv2d-40          [-1, 240, 45, 49]           6,000\n",
      "      BatchNorm2d-41          [-1, 240, 45, 49]             480\n",
      "            ReLU6-42          [-1, 240, 45, 49]               0\n",
      "           Conv2d-43           [-1, 40, 45, 49]           9,600\n",
      "      BatchNorm2d-44           [-1, 40, 45, 49]              80\n",
      "      MBConvBlock-45           [-1, 40, 45, 49]               0\n",
      "           Conv2d-46          [-1, 240, 45, 49]           9,600\n",
      "      BatchNorm2d-47          [-1, 240, 45, 49]             480\n",
      "            ReLU6-48          [-1, 240, 45, 49]               0\n",
      "           Conv2d-49          [-1, 240, 23, 25]           2,160\n",
      "      BatchNorm2d-50          [-1, 240, 23, 25]             480\n",
      "            ReLU6-51          [-1, 240, 23, 25]               0\n",
      "           Conv2d-52           [-1, 80, 23, 25]          19,200\n",
      "      BatchNorm2d-53           [-1, 80, 23, 25]             160\n",
      "      MBConvBlock-54           [-1, 80, 23, 25]               0\n",
      "           Conv2d-55          [-1, 480, 23, 25]          38,400\n",
      "      BatchNorm2d-56          [-1, 480, 23, 25]             960\n",
      "            ReLU6-57          [-1, 480, 23, 25]               0\n",
      "           Conv2d-58          [-1, 480, 23, 25]           4,320\n",
      "      BatchNorm2d-59          [-1, 480, 23, 25]             960\n",
      "            ReLU6-60          [-1, 480, 23, 25]               0\n",
      "           Conv2d-61           [-1, 80, 23, 25]          38,400\n",
      "      BatchNorm2d-62           [-1, 80, 23, 25]             160\n",
      "      MBConvBlock-63           [-1, 80, 23, 25]               0\n",
      "           Conv2d-64          [-1, 480, 23, 25]          38,400\n",
      "      BatchNorm2d-65          [-1, 480, 23, 25]             960\n",
      "            ReLU6-66          [-1, 480, 23, 25]               0\n",
      "           Conv2d-67          [-1, 480, 23, 25]           4,320\n",
      "      BatchNorm2d-68          [-1, 480, 23, 25]             960\n",
      "            ReLU6-69          [-1, 480, 23, 25]               0\n",
      "           Conv2d-70           [-1, 80, 23, 25]          38,400\n",
      "      BatchNorm2d-71           [-1, 80, 23, 25]             160\n",
      "      MBConvBlock-72           [-1, 80, 23, 25]               0\n",
      "           Conv2d-73          [-1, 480, 23, 25]          38,400\n",
      "      BatchNorm2d-74          [-1, 480, 23, 25]             960\n",
      "            ReLU6-75          [-1, 480, 23, 25]               0\n",
      "           Conv2d-76          [-1, 480, 23, 25]          12,000\n",
      "      BatchNorm2d-77          [-1, 480, 23, 25]             960\n",
      "            ReLU6-78          [-1, 480, 23, 25]               0\n",
      "           Conv2d-79          [-1, 112, 23, 25]          53,760\n",
      "      BatchNorm2d-80          [-1, 112, 23, 25]             224\n",
      "      MBConvBlock-81          [-1, 112, 23, 25]               0\n",
      "           Conv2d-82          [-1, 672, 23, 25]          75,264\n",
      "      BatchNorm2d-83          [-1, 672, 23, 25]           1,344\n",
      "            ReLU6-84          [-1, 672, 23, 25]               0\n",
      "           Conv2d-85          [-1, 672, 23, 25]          16,800\n",
      "      BatchNorm2d-86          [-1, 672, 23, 25]           1,344\n",
      "            ReLU6-87          [-1, 672, 23, 25]               0\n",
      "           Conv2d-88          [-1, 112, 23, 25]          75,264\n",
      "      BatchNorm2d-89          [-1, 112, 23, 25]             224\n",
      "      MBConvBlock-90          [-1, 112, 23, 25]               0\n",
      "           Conv2d-91          [-1, 672, 23, 25]          75,264\n",
      "      BatchNorm2d-92          [-1, 672, 23, 25]           1,344\n",
      "            ReLU6-93          [-1, 672, 23, 25]               0\n",
      "           Conv2d-94          [-1, 672, 23, 25]          16,800\n",
      "      BatchNorm2d-95          [-1, 672, 23, 25]           1,344\n",
      "            ReLU6-96          [-1, 672, 23, 25]               0\n",
      "           Conv2d-97          [-1, 112, 23, 25]          75,264\n",
      "      BatchNorm2d-98          [-1, 112, 23, 25]             224\n",
      "      MBConvBlock-99          [-1, 112, 23, 25]               0\n",
      "          Conv2d-100          [-1, 672, 23, 25]          75,264\n",
      "     BatchNorm2d-101          [-1, 672, 23, 25]           1,344\n",
      "           ReLU6-102          [-1, 672, 23, 25]               0\n",
      "          Conv2d-103          [-1, 672, 12, 13]          16,800\n",
      "     BatchNorm2d-104          [-1, 672, 12, 13]           1,344\n",
      "           ReLU6-105          [-1, 672, 12, 13]               0\n",
      "          Conv2d-106          [-1, 192, 12, 13]         129,024\n",
      "     BatchNorm2d-107          [-1, 192, 12, 13]             384\n",
      "     MBConvBlock-108          [-1, 192, 12, 13]               0\n",
      "          Conv2d-109         [-1, 1152, 12, 13]         221,184\n",
      "     BatchNorm2d-110         [-1, 1152, 12, 13]           2,304\n",
      "           ReLU6-111         [-1, 1152, 12, 13]               0\n",
      "          Conv2d-112         [-1, 1152, 12, 13]          28,800\n",
      "     BatchNorm2d-113         [-1, 1152, 12, 13]           2,304\n",
      "           ReLU6-114         [-1, 1152, 12, 13]               0\n",
      "          Conv2d-115          [-1, 192, 12, 13]         221,184\n",
      "     BatchNorm2d-116          [-1, 192, 12, 13]             384\n",
      "     MBConvBlock-117          [-1, 192, 12, 13]               0\n",
      "          Conv2d-118         [-1, 1152, 12, 13]         221,184\n",
      "     BatchNorm2d-119         [-1, 1152, 12, 13]           2,304\n",
      "           ReLU6-120         [-1, 1152, 12, 13]               0\n",
      "          Conv2d-121         [-1, 1152, 12, 13]          28,800\n",
      "     BatchNorm2d-122         [-1, 1152, 12, 13]           2,304\n",
      "           ReLU6-123         [-1, 1152, 12, 13]               0\n",
      "          Conv2d-124          [-1, 192, 12, 13]         221,184\n",
      "     BatchNorm2d-125          [-1, 192, 12, 13]             384\n",
      "     MBConvBlock-126          [-1, 192, 12, 13]               0\n",
      "          Conv2d-127         [-1, 1152, 12, 13]         221,184\n",
      "     BatchNorm2d-128         [-1, 1152, 12, 13]           2,304\n",
      "           ReLU6-129         [-1, 1152, 12, 13]               0\n",
      "          Conv2d-130         [-1, 1152, 12, 13]          28,800\n",
      "     BatchNorm2d-131         [-1, 1152, 12, 13]           2,304\n",
      "           ReLU6-132         [-1, 1152, 12, 13]               0\n",
      "          Conv2d-133          [-1, 192, 12, 13]         221,184\n",
      "     BatchNorm2d-134          [-1, 192, 12, 13]             384\n",
      "     MBConvBlock-135          [-1, 192, 12, 13]               0\n",
      "          Conv2d-136         [-1, 1152, 12, 13]         221,184\n",
      "     BatchNorm2d-137         [-1, 1152, 12, 13]           2,304\n",
      "           ReLU6-138         [-1, 1152, 12, 13]               0\n",
      "          Conv2d-139         [-1, 1152, 12, 13]          10,368\n",
      "     BatchNorm2d-140         [-1, 1152, 12, 13]           2,304\n",
      "           ReLU6-141         [-1, 1152, 12, 13]               0\n",
      "          Conv2d-142          [-1, 320, 12, 13]         368,640\n",
      "     BatchNorm2d-143          [-1, 320, 12, 13]             640\n",
      "     MBConvBlock-144          [-1, 320, 12, 13]               0\n",
      "          Conv2d-145         [-1, 1280, 12, 13]         409,600\n",
      "     BatchNorm2d-146         [-1, 1280, 12, 13]           2,560\n",
      "           ReLU6-147         [-1, 1280, 12, 13]               0\n",
      "AdaptiveAvgPool2d-148           [-1, 1280, 1, 1]               0\n",
      "         Dropout-149                 [-1, 1280]               0\n",
      "          Linear-150               [-1, 275544]     352,971,864\n",
      "================================================================\n",
      "Total params: 356,342,584\n",
      "Trainable params: 356,342,584\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.05\n",
      "Forward/backward pass size (MB): 439.31\n",
      "Params size (MB): 1359.34\n",
      "Estimated Total Size (MB): 1799.70\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_name = \"efficientnet_lite0\"\n",
    "num_outputs = 275544\n",
    "model = build_efficientnet_lite(model_name, num_outputs)\n",
    "device = torch.device('cpu')\n",
    "model = model.to(device)\n",
    "summary(model,input_size=(2,356,387))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pass 1 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 356, 387)\n",
      "idasN.shape: torch.Size([356, 387])\n",
      "qdasN.shape: torch.Size([356, 387])\n",
      "(2, 356, 387)\n",
      "!!! iguales !!!\n"
     ]
    }
   ],
   "source": [
    "path1 = r'D:\\OneDrive\\Documents\\Maestria_Biomedica\\Imagenes_Medicas\\model_cubdl\\test_image'\n",
    "files = os.listdir(path1)\n",
    "\n",
    "for file in files:\n",
    "    if file.endswith(\".hdf5\"):\n",
    "\n",
    "        origin, acq = get_name_and_acq(file)\n",
    "        # print(os.path.abspath(file))\n",
    "        full_path = os.path.abspath(file)\n",
    "        if origin == 'TSH':\n",
    "            P = TSHData(path1, acq)\n",
    "            xlims = [P.ele_pos[0, 0], P.ele_pos[-1, 0]]\n",
    "            zlims = [10e-3, 45e-3]\n",
    "\n",
    "        wvln = P.c / P.fc\n",
    "        dx = wvln / 2.5\n",
    "        dz = dx  # Use square pixels\n",
    "        grid = make_pixel_grid(xlims, zlims, dx, dz)\n",
    "        fnum = 1\n",
    "\n",
    "        # make data from 1 angle\n",
    "        x = (P.idata, P.qdata)\n",
    "        idx = len(P.angles) // 2  # Choose center angle\n",
    "        das1 = DAS_PW(P, grid, idx, rxfnum=fnum)\n",
    "        idas1, qdas1 = das1(x)\n",
    "        idas1, qdas1 = idas1.detach().cpu().numpy(), qdas1.detach().cpu().numpy()\n",
    "\n",
    "        input_data = np.stack((idas1, qdas1), axis=0)\n",
    "        print(input_data.shape)\n",
    "\n",
    "        # make data from all angles\n",
    "        dasN = DAS_PW(P, grid, rxfnum=fnum)\n",
    "        idasN, qdasN = dasN(x)\n",
    "        print(\"idasN.shape: \" + str(idasN.shape))\n",
    "        print(\"qdasN.shape: \" + str(qdasN.shape))\n",
    "        idasN, qdasN = idasN.detach().cpu().numpy(), qdasN.detach().cpu().numpy()\n",
    "        target = np.stack((idasN, qdasN), axis=0)\n",
    "        print(target.shape)\n",
    "\n",
    "        if (input_data.shape == target.shape):\n",
    "            print(\"!!! iguales !!!\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10 20 30]\n",
      " [40 50 60]\n",
      " [70 80 90]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 2, 3],[4, 5, 6],[7, 8, 9]])\n",
    "b = np.array([[10, 20, 30],[40, 50, 60],[70, 80, 90]])\n",
    "c = np.stack((a, b), axis=0)\n",
    "print(c[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_torch = torch.from_numpy(input_data)\n",
    "out = model(input_torch[None,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 275544])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 356, 387])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_reshape = torch.reshape(out, (2,356,387))\n",
    "out_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 11, 12],\n",
       "        [13, 14, 15],\n",
       "        [16, 17, 18]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edc2ed36384d22acd0427a0b15da46384863e4aea8aad8aae706f10aa40d3084"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('cubdl': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
